{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import config   \n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from modules.corpus import Corpus\n",
    "from program import full_search_engine_proc\n",
    "from utils.tools import clean_text_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(path, 'data')\n",
    "collection = list()\n",
    "\n",
    "def run_process(arxiv_kw:str, subreddit:str, keywords:str) -> pd.DataFrame:\n",
    "    tokens_kw = clean_text_util(keywords)\n",
    "    try:\n",
    "        collection = full_search_engine_proc(arxiv_kw=arxiv_kw, subreddit_kw=subreddit)\n",
    "    except TypeError as t:\n",
    "        logging.error(t)\n",
    "        raise TypeError\n",
    "    try:\n",
    "        corpus = Corpus()\n",
    "\n",
    "        max_articles = 10\n",
    "        for i in range(max_articles):\n",
    "            doc = collection[i]\n",
    "            corpus.add(author=doc.author , doc=doc)\n",
    "                \n",
    "        vocab = corpus.stats()\n",
    "        vocab = vocab.sort_values('count', ascending=False)\n",
    "                    \n",
    "        from program import search_engine\n",
    "        results = search_engine(collection, tokens_kw)\n",
    "        \n",
    "    except TypeError as t:\n",
    "        logging.error(t)\n",
    "        raise TypeError\n",
    "    except ValueError as v:\n",
    "        logging.error(v)\n",
    "        raise ValueError\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Reddit data \n",
    "Please run following cell, if you want to change key word run again after make changes in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdaccb349e0434483d83e696df6352c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Subreddit:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0382d8e1c5ee49a7aa093ae84e79cf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='MachineLearning')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6d0b683e5e49ff915eeae6f0a8f532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Arxiv Keyword:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa55c04691146a0bf68efae9de618bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='machine learning')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cca14821e004b79870bbdd71159f5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Keywords:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374ffc0b78884a0cbfdbe14cbb3bd1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Llama machine learning')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4679bcadba4cacb415de563060d906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run Function', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Document URL  Similarity Score                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Document Text\n",
      "0  http://arxiv.org/abs/1707.09562v3          0.782062                                                                                                                                                                                                                                                               We conduct an empirical study of machine learning functionalities provided by major cloud service providers, which we call machine learning clouds. Machine learning clouds hold the promise of hiding all the sophistication of running large-scale machine learning: Instead of specifying how to run a machine learning task, users only specify what machine learning task to run and the cloud figures out the rest. Raising the level of abstraction, however, rarely comes free - a performance penalty is possible. How good, then, are current machine learning clouds on real-world machine learning workloads?   We study this question with a focus on binary classication problems. We present mlbench, a novel benchmark constructed by harvesting datasets from Kaggle competitions. We then compare the performance of the top winning code available from Kaggle with that of running machine learning clouds from both Azure and Amazon on mlbench. Our comparative study reveals the strength and weakness of existing machine learning clouds and points out potential future directions for improvement.\n",
      "1  http://arxiv.org/abs/1903.08801v1          0.716928  Traditional machine learning algorithms use data from databases that are mutable, and therefore the data cannot be fully trusted. Also, the machine learning process is difficult to automate. This paper proposes building a trustable machine learning system by using blockchain technology, which can store data in a permanent and immutable way. In addition, smart contracts are used to automate the machine learning process. This paper makes three contributions. First, it establishes a link between machine learning technology and blockchain technology. Previously, machine learning and blockchain have been considered two independent technologies without an obvious link. Second, it proposes a unified analytical framework for trustable machine learning by using blockchain technology. This unified framework solves both the trustability and automation issues in machine learning. Third, it enables a computer to translate core machine learning implementation from a single thread on a single machine to multiple threads on multiple machines running with blockchain by using a unified approach. The paper uses association rule mining as an example to demonstrate how trustable machine learning can be implemented with blockchain, and it shows how this approach can be used to analyze opioid prescriptions to help combat the opioid crisis.\n",
      "2  http://arxiv.org/abs/2312.03120v1          0.692935                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       With the advance of the powerful heterogeneous, parallel and distributed computing systems and ever increasing immense amount of data, machine learning has become an indispensable part of cutting-edge technology, scientific research and consumer products. In this study, we present a review of modern machine and deep learning. We provide a high-level overview for the latest advanced machine learning algorithms, applications, and frameworks. Our discussion encompasses parallel distributed learning, deep learning as well as federated learning. As a result, our work serves as an introductory text to the vast field of modern machine learning.\n",
      "3  http://arxiv.org/abs/2108.07915v1          0.671932                                   Machine learning is disruptive. At the same time, machine learning can only succeed by collaboration among many parties in multiple steps naturally as pipelines in an eco-system, such as collecting data for possible machine learning applications, collaboratively training models by multiple parties and delivering machine learning services to end users. Data is critical and penetrating in the whole machine learning pipelines. As machine learning pipelines involve many parties and, in order to be successful, have to form a constructive and dynamic eco-system, marketplaces and data pricing are fundamental in connecting and facilitating those many parties. In this article, we survey the principles and the latest research development of data pricing in machine learning pipelines. We start with a brief review of data marketplaces and pricing desiderata. Then, we focus on pricing in three important steps in machine learning pipelines. To understand pricing in the step of training data collection, we review pricing raw data sets and data labels. We also investigate pricing in the step of collaborative training of machine learning models, and overview pricing machine learning models for end users in the step of machine learning deployment. We also discuss a series of possible future directions.\n",
      "4  http://arxiv.org/abs/1909.01866v1          0.650945                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Bias is known to be an impediment to fair decisions in many domains such as human resources, the public sector, health care etc. Recently, hope has been expressed that the use of machine learning methods for taking such decisions would diminish or even resolve the problem. At the same time, machine learning experts warn that machine learning models can be biased as well. In this article, our goal is to explain the issue of bias in machine learning from a technical perspective and to illustrate the impact that biased data can have on a machine learning model. To reach such a goal, we develop interactive plots to visualizing the bias learned from synthetic data.\n"
     ]
    }
   ],
   "source": [
    "subreddit_label = widgets.Label(value='Subreddit:')\n",
    "subreddit = widgets.Text(value='MachineLearning')\n",
    "display(subreddit_label)\n",
    "display(subreddit)\n",
    "\n",
    "arxiv_kw_label = widgets.Label(value='Arxiv Keyword:')\n",
    "arxiv_kw = widgets.Text(value='machine learning')\n",
    "display(arxiv_kw_label)\n",
    "display(arxiv_kw)\n",
    "\n",
    "keywords_label = widgets.Label(value='Keywords:')\n",
    "keywords = widgets.Text(value='Llama machine learning')\n",
    "display(keywords_label)\n",
    "display(keywords)\n",
    "\n",
    "# Create the button widget\n",
    "button = widgets.Button(description=\"Run Function\")\n",
    "\n",
    "# Define a function to pass the values of the labels to the button\n",
    "def pass_values_to_button(button):\n",
    "    button.subreddit_kw = subreddit.value\n",
    "    button.arxiv_kw = arxiv_kw.value\n",
    "    button.keywords = keywords.value\n",
    "    result = run_process(\n",
    "        arxiv_kw=button.arxiv_kw,\n",
    "        subreddit=button.subreddit_kw, \n",
    "        keywords=button.keywords\n",
    "        )\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    # Show first 5 results\n",
    "    print(result.iloc[:5].to_string())\n",
    "\n",
    "# Associate the function with the button's on_click event\n",
    "button.on_click(pass_values_to_button)\n",
    "\n",
    "# Display the button\n",
    "display(button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_lyon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
