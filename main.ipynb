{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine\n",
    "\n",
    "This Jupyter Notebook contains a search engine program. The program allows you to search for articles based on an Arxiv keyword, a subreddit, and general keywords. \n",
    "\n",
    "To use the search engine, follow these steps:\n",
    "1. Fill in the three labels with your desired values for the Arxiv keyword, subreddit, and general keyword.\n",
    "2. Click the \"Search\" button.\n",
    "3. The program will display 5 results, including the article URL, a similarity score with your keywords, and an overview of the article.\n",
    "\n",
    "Please note that this program requires the necessary modules and configurations to be set up correctly. Go to README.md and know all the pre requirements before running the program.\n",
    "\n",
    "Happy searching! :rocket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import config   \n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from modules.corpus import Corpus\n",
    "from utils.program import full_search_engine_proc\n",
    "from utils.tools import clean_text_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application set up\n",
    "\n",
    "path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(path, 'data')\n",
    "collection = list()\n",
    "\n",
    "def run_process(arxiv_kw:str, subreddit:str, keywords:str) -> pd.DataFrame:\n",
    "    tokens_kw = clean_text_util(keywords)\n",
    "    try:\n",
    "        corpus = full_search_engine_proc(arxiv_kw=arxiv_kw, subreddit_kw=subreddit)\n",
    "    except TypeError as t:\n",
    "        logging.error(t)\n",
    "        raise TypeError\n",
    "    try:\n",
    "        # corpus = Corpus()\n",
    "\n",
    "        # max_articles = 10\n",
    "        # for i in range(max_articles):\n",
    "        #     doc = collection[i]\n",
    "        #     corpus.add(author=doc.author , doc=doc)\n",
    "                \n",
    "        vocab = corpus.get_stats()\n",
    "        vocab = vocab.sort_values('count', ascending=False)\n",
    "                    \n",
    "        from utils.program import search_engine\n",
    "        results = search_engine(corpus.get_all_docs(), tokens_kw)\n",
    "        \n",
    "    except TypeError as t:\n",
    "        logging.error(t)\n",
    "        raise TypeError\n",
    "    except ValueError as v:\n",
    "        logging.error(v)\n",
    "        raise ValueError\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb1ab057f934bae996daf16513bb9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Subreddit:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acdc15e989b412b9e9f054530c4c00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='MachineLearning')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385e76b855454da28c14ea9c2297a3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Arxiv Keyword:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab9edd9c1ad4f2b9462080b9d39f824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='machine learning')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c4b8f3defe4ec181099ef5476529a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Keywords:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7031f3624d4a5aa9a088386e4355c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Llama machine learning')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221411f9b3a74310959b031e65ab54f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Search', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n",
      "ERROR:root:'Corpus' object is not iterable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mrun_process\u001b[0;34m(arxiv_kw, subreddit, keywords)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     collection \u001b[38;5;241m=\u001b[39m \u001b[43mfull_search_engine_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marxiv_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marxiv_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubreddit_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubreddit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m t:\n",
      "File \u001b[0;32m~/Documents/code/lyon2/python_programation/search_engine/utils/program.py:94\u001b[0m, in \u001b[0;36mfull_search_engine_proc\u001b[0;34m(arxiv_kw, subreddit_kw)\u001b[0m\n\u001b[1;32m     90\u001b[0m documents \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     91\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreddit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyword\u001b[39m\u001b[38;5;124m'\u001b[39m:subreddit_kw},\n\u001b[1;32m     92\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marxiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyword\u001b[39m\u001b[38;5;124m'\u001b[39m:arxiv_kw}\n\u001b[1;32m     93\u001b[0m ]\n\u001b[0;32m---> 94\u001b[0m search_results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m search_documents(documents)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(search_results\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Corpus' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m, in \u001b[0;36mpass_values_to_button\u001b[0;34m(button)\u001b[0m\n\u001b[1;32m     24\u001b[0m button\u001b[38;5;241m.\u001b[39marxiv_kw \u001b[38;5;241m=\u001b[39m arxiv_kw\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     25\u001b[0m button\u001b[38;5;241m.\u001b[39mkeywords \u001b[38;5;241m=\u001b[39m keywords\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m---> 26\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_process\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43marxiv_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marxiv_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubreddit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubreddit_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeywords\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mrun_process\u001b[0;34m(arxiv_kw, subreddit, keywords)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m     12\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(t)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m Corpus()\n",
      "\u001b[0;31mTypeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Form set up\n",
    "\n",
    "subreddit_label = widgets.Label(value='Subreddit:')\n",
    "subreddit = widgets.Text(value='MachineLearning')\n",
    "display(subreddit_label)\n",
    "display(subreddit)\n",
    "\n",
    "arxiv_kw_label = widgets.Label(value='Arxiv Keyword:')\n",
    "arxiv_kw = widgets.Text(value='machine learning')\n",
    "display(arxiv_kw_label)\n",
    "display(arxiv_kw)\n",
    "\n",
    "keywords_label = widgets.Label(value='Keywords:')\n",
    "keywords = widgets.Text(value='Llama machine learning')\n",
    "display(keywords_label)\n",
    "display(keywords)\n",
    "\n",
    "# Create the button widget\n",
    "button = widgets.Button(description=\"Search\")\n",
    "\n",
    "# Function to run when button is clicked\n",
    "def pass_values_to_button(button):\n",
    "    button.subreddit_kw = subreddit.value\n",
    "    button.arxiv_kw = arxiv_kw.value\n",
    "    button.keywords = keywords.value\n",
    "    result = run_process(\n",
    "        arxiv_kw=button.arxiv_kw,\n",
    "        subreddit=button.subreddit_kw, \n",
    "        keywords=button.keywords\n",
    "        )\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    # Show first 5 results\n",
    "    print(result.iloc[:5].to_string())\n",
    "\n",
    "# Associate the function with the button's on_click event\n",
    "button.on_click(pass_values_to_button)\n",
    "\n",
    "# Display the button\n",
    "display(button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
